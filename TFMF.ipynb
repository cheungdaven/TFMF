{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Install Dependencies</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install progressbar --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install envoy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data loader </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import envoy\n",
    "import progressbar\n",
    "import sys\n",
    "\n",
    "class Data(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.users = {}\n",
    "        self.items = {}\n",
    "        self.nusers = 0\n",
    "        self.nitems = 0\n",
    "        self.include_time = False\n",
    "\n",
    "    def update_user_item(self, user, item):\n",
    "        if user not in self.users:\n",
    "            self.users[user] = self.nusers\n",
    "            self.nusers += 1\n",
    "        if item not in self.items:\n",
    "            self.items[item] = self.nitems\n",
    "            self.nitems += 1\n",
    "\n",
    "    def import_data(self, filename, parser, shape=None, contains_header=False, debug=False):\n",
    "        r = envoy.run('wc -l {}'.format(filename))\n",
    "        num_lines = int(r.std_out.strip().partition(' ')[0])\n",
    "        bar = progressbar.ProgressBar(maxval=num_lines, widgets=[\"Loading data: \",\n",
    "                                                                 progressbar.Bar(\n",
    "                                                                     '=', '[', ']'),\n",
    "                                                                 ' ', progressbar.Percentage(),\n",
    "\n",
    "                                                                 ' ', progressbar.ETA()]).start()\n",
    "        I, J, V = [], [], []\n",
    "        with open(filename) as f:\n",
    "            if contains_header:\n",
    "                f.readline()\n",
    "            for i, line in enumerate(f):\n",
    "                if (i % 1000) == 0:\n",
    "                    bar.update(i % bar.maxval)\n",
    "                try:\n",
    "                    userid, itemid, rating = parser.parse(line)\n",
    "                    self.update_user_item(userid, itemid)\n",
    "                    uid = self.users[userid]\n",
    "                    iid = self.items[itemid]\n",
    "                    I.append(uid)\n",
    "                    J.append(iid)\n",
    "                    V.append(float(rating))\n",
    "                except:\n",
    "                    if debug:\n",
    "                        print \"Ignoring Input: \", line,\n",
    "                    continue\n",
    "        bar.finish()\n",
    "        if shape is not None:\n",
    "            _shape = (self.nusers if shape[0] is None else shape[0],\n",
    "                      self.nitems if shape[1] is None else shape[1])\n",
    "            R = scipy.sparse.coo_matrix(\n",
    "                (V, (I, J)), shape=_shape)\n",
    "        else:\n",
    "            R = scipy.sparse.coo_matrix(\n",
    "                (V, (I, J)), shape=(self.nusers, self.nitems))\n",
    "        self.R = R.tocsr()\n",
    "        self.R.eliminate_zeros()\n",
    "        sys.stdout.flush()\n",
    "        return self.R\n",
    "\n",
    "    def filter(self, n_users=5, n_items=5, iscount=False):\n",
    "        while True:\n",
    "            if iscount:\n",
    "                Rcp = self.R.copy()\n",
    "                Rcp.data[:] = 1.0\n",
    "            else:\n",
    "                Rcp = self.R\n",
    "            user_stats = Rcp.sum(axis=1)\n",
    "            item_stats = Rcp.sum(axis=0)\n",
    "            filter_user = np.ravel((user_stats < n_users) * 1)\n",
    "            filter_user_cum = np.cumsum(filter_user)\n",
    "            filter_item = np.ravel((item_stats < n_items) * 1)\n",
    "            filter_item_cum = np.cumsum(filter_item)\n",
    "            if (filter_user_cum[-1] == 0) and (filter_item_cum[-1] == 0):\n",
    "                break\n",
    "\n",
    "            m, n = self.R.shape\n",
    "\n",
    "            # filter User item\n",
    "            I, J, V = [], [], []\n",
    "            data, ri, rptr = self.R.data, self.R.indices, self.R.indptr\n",
    "            for i in xrange(m):\n",
    "                indices = range(rptr[i], rptr[i + 1])\n",
    "                items = ri[indices]\n",
    "                ratings = data[indices]\n",
    "                for j, item in enumerate(items):\n",
    "                    if (filter_user[i] == 0) and (filter_item[item] == 0):\n",
    "                        I.append(i - filter_user_cum[i])\n",
    "                        J.append(item - filter_item_cum[item])\n",
    "                        V.append(ratings[j])\n",
    "            R = scipy.sparse.coo_matrix((V, (I, J)),\n",
    "                                        shape=(m - filter_user_cum[-1],\n",
    "                                               n - filter_item_cum[-1]))\n",
    "            self.R = R.tocsr()\n",
    "\n",
    "            inv_users = {v: k for k, v in self.users.items()}\n",
    "            inv_items = {v: k for k, v in self.items.items()}\n",
    "\n",
    "            for i in range(m):\n",
    "                if filter_user[i] == 1:\n",
    "                    del self.users[inv_users[i]]\n",
    "                else:\n",
    "                    self.users[inv_users[i]] -= filter_user_cum[i]\n",
    "\n",
    "            for i in range(n):\n",
    "                if filter_item[i] == 1:\n",
    "                    del self.items[inv_items[i]]\n",
    "                else:\n",
    "                    self.items[inv_items[i]] -= filter_item_cum[i]\n",
    "\n",
    "def loadDataset(filename, usermap, itemmap, parser, shape=None):\n",
    "    r = envoy.run('wc -l {}'.format(filename))\n",
    "    num_lines = int(r.std_out.strip().partition(' ')[0])\n",
    "    bar = progressbar.ProgressBar(maxval=num_lines, widgets=[\"Loading data: \",\n",
    "                                                             progressbar.Bar(\n",
    "                                                                 '=', '[', ']'),\n",
    "                                                             ' ', progressbar.Percentage(),\n",
    "\n",
    "                                                             ' ', progressbar.ETA()]).start()\n",
    "    I, J, V = [], [], []\n",
    "    cold = []\n",
    "    with open(filename) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if (i % 1000) == 0:\n",
    "                bar.update(i % bar.maxval)\n",
    "            userid, itemid, rating = parser.parse(line)\n",
    "            if userid not in usermap or itemid not in itemmap:\n",
    "                cold.append((userid, itemid, rating))\n",
    "                continue\n",
    "            uid = usermap[userid]\n",
    "            iid = itemmap[itemid]\n",
    "            I.append(uid)\n",
    "            J.append(iid)\n",
    "            V.append(float(rating))\n",
    "    bar.finish()\n",
    "    if shape is not None:\n",
    "        R = scipy.sparse.coo_matrix((V, (I, J)), shape=shape)\n",
    "    else:\n",
    "        R = scipy.sparse.coo_matrix(\n",
    "            (V, (I, J)), shape=(len(usermap), len(itemmap)))\n",
    "    R = R.tocsr()\n",
    "\n",
    "    return R, cold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Line parser\n",
    "class UserItemRatingParser:\n",
    "    def __init__(self, delim=\",\", threshold = 60):\n",
    "        self.delim = delim\n",
    "    def parse(self, line):\n",
    "        user, item, rating = line.strip().split(self.delim)\n",
    "        return (user, item, rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Biased matrix factorisation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class TensorflowMF:\n",
    "    \"\"\"\n",
    "    Biased matrix factorisation model using TensorFlow\n",
    "    r_ui = b + b_u + b_i + < U_u, V_i >\n",
    "    \"\"\"\n",
    "    def __init__(self, num_users, num_items, rank, reg):\n",
    "        self.rank = rank\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.reg = reg\n",
    "        self.initialize_values()\n",
    "        \n",
    "    def initialize_values(self):\n",
    "        self.b =  tf.Variable(0.0, name=\"global_bias\")\n",
    "        self.b_u =  tf.Variable(tf.truncated_normal([self.num_users, 1], stddev=0.01, mean=0), name=\"user_bias\")\n",
    "        self.b_i =  tf.Variable(tf.truncated_normal([self.num_items, 1], stddev=0.01, mean=0), name=\"item_bias\")\n",
    "        self.U = tf.Variable(tf.truncated_normal([self.num_users, rank], stddev=0.01, mean=0), name=\"users\")\n",
    "        self.V = tf.Variable(tf.truncated_normal([self.num_items, rank], stddev=0.01, mean=0), name=\"items\")\n",
    "          \n",
    "             \n",
    "    def predict(self, users, items):\n",
    "        U_ = tf.squeeze(tf.nn.embedding_lookup(self.U, users))\n",
    "        V_ = tf.squeeze(tf.nn.embedding_lookup(self.V, items))\n",
    "        prediction = tf.nn.sigmoid((tf.reduce_sum(tf.mul(U_, V_), reduction_indices=[1]))) \n",
    "        ubias = tf.squeeze(tf.nn.embedding_lookup(self.b_u, users))\n",
    "        ibias = tf.squeeze(tf.nn.embedding_lookup(self.b_i, items))\n",
    "        prediction =   self.b + ubias + ibias + tf.squeeze(prediction)\n",
    "        return prediction\n",
    "\n",
    "    def regLoss(self):\n",
    "        reg_loss = 0\n",
    "        reg_loss +=  tf.reduce_sum(tf.square(self.U))\n",
    "        reg_loss +=  tf.reduce_sum(tf.square(self.V))\n",
    "        reg_loss += tf.reduce_sum(tf.square(self.b_u))\n",
    "        reg_loss += tf.reduce_sum(tf.square(self.b_i))\n",
    "        return reg_loss * self.reg\n",
    "    \n",
    "    def loss(self, users_items_ratings):\n",
    "        users, items, ratings = users_items_ratings\n",
    "        prediction = self.predict(users, items)\n",
    "        err_loss = tf.nn.l2_loss(prediction - ratings) \n",
    "        reg_loss = self.regLoss()\n",
    "        self.total_loss = err_loss + reg_loss\n",
    "        tf.scalar_summary(\"loss\", self.total_loss)\n",
    "        return self.total_loss\n",
    "    \n",
    "    def fit(self, users_items_ratings, test_users_items_ratings=None, n_iter=10):\n",
    "        cost = self.loss(users_items_ratings)\n",
    "        optimiser = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            users, items, ratings = users_items_ratings\n",
    "            for i in range(n_iter):\n",
    "                sess.run(optimiser)\n",
    "                if i%20 == 0:\n",
    "                    print self.evalTestError(test_users_items_ratings).eval()\n",
    "                    \n",
    "    def evalTestError(self, test_user_items_ratings):\n",
    "        testusers, testitems, testratings = test_user_items_ratings\n",
    "        testprediction = self.predict(testusers, testitems)\n",
    "        return tf.sqrt(tf.nn.l2_loss(testprediction - testratings) * 2.0 / len(testusers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Experiments</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input data file in format <userid>\\t<itemid>\\t<rating>\n",
    "\n",
    "train_path = \"/data3/ssedhain/datasets/movielens/1M/90folds/train.1\" \n",
    "test_path = \"/data3/ssedhain/datasets/movielens/1M/90folds/test.1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sparseMatrix2UserItemRating(_mat):\n",
    "    temp = _mat.tocoo()\n",
    "    user = temp.row.reshape(-1,1)\n",
    "    item = temp.col.reshape(-1,1)\n",
    "    rating = temp.data\n",
    "    return user, item, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = UserItemRatingParser(\"\\t\")\n",
    "d = Data()\n",
    "d.import_data(train_path, parser)\n",
    "train = d.R\n",
    "test, cold_start_user_item_ratings = loadDataset(test_path, d.users, d.items, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_users, num_items = train.shape\n",
    "rank = 5\n",
    "reg = 1.0\n",
    "n_iter = 400\n",
    "t = TensorflowMF(num_users, num_items, rank, reg)\n",
    "users_items_ratings = sparseMatrix2UserItemRating(train)\n",
    "test_users_items_ratings = sparseMatrix2UserItemRating(test)\n",
    "t.fit(users_items_ratings, test_users_items_ratings, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
